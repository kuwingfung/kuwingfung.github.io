<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://kuwingfung.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kuwingfung.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-26T20:08:37+00:00</updated><id>https://kuwingfung.github.io/feed.xml</id><title type="html">Max W.F. Ku</title><subtitle>Academic page of Max Ku. </subtitle><entry><title type="html">Paper Review - PDAE, DisDiff and InfoDiffusion</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-pdae-disdiff-and-infodiffusion/" rel="alternate" type="text/html" title="Paper Review - PDAE, DisDiff and InfoDiffusion"/><published>2024-08-26T05:56:59+00:00</published><updated>2024-08-26T05:56:59+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---pdae-disdiff-and-infodiffusion</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-pdae-disdiff-and-infodiffusion/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Literature review on Unsupervised Representation Learning in diffusion models.]]></summary></entry><entry><title type="html">Paper Review - ColorPeel</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-colorpeel/" rel="alternate" type="text/html" title="Paper Review - ColorPeel"/><published>2024-07-16T16:56:41+00:00</published><updated>2024-07-16T16:56:41+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---colorpeel</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-colorpeel/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[An interesting paper from ECCV2024. It talks about the color and shape disentanglement on Text-to-Image models. The solution is simple yet effective.]]></summary></entry><entry><title type="html">Paper Review - Disentangled Contrastive Learning on Graphs</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-disentangled-contrastive-learning-on-graphs/" rel="alternate" type="text/html" title="Paper Review - Disentangled Contrastive Learning on Graphs"/><published>2024-07-16T16:51:51+00:00</published><updated>2024-07-16T16:51:51+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---disentangled-contrastive-learning-on-graphs</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-disentangled-contrastive-learning-on-graphs/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Revisit Contrastive learning Contrastive learning is an instance-wise discriminative approach that aims at making]]></summary></entry><entry><title type="html">Paper Review - T-Cell Receptor meets VAE</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-t-cell-receptor-meets-vae/" rel="alternate" type="text/html" title="Paper Review - T-Cell Receptor meets VAE"/><published>2024-07-07T05:34:32+00:00</published><updated>2024-07-07T05:34:32+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---t-cell-receptor-meets-vae</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-t-cell-receptor-meets-vae/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[T-cell receptors (TCR) bind to certain antigens found on abnormal cells. We can perform TCR engineering with VAEs.]]></summary></entry><entry><title type="html">Paper Review - Evolutionary Scale Modeling</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-evolutionary-scale-modeling/" rel="alternate" type="text/html" title="Paper Review - Evolutionary Scale Modeling"/><published>2024-06-28T07:30:26+00:00</published><updated>2024-06-28T07:30:26+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---evolutionary-scale-modeling</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-evolutionary-scale-modeling/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[ESM-1 and ESM-2 refer to protein language models developed by Facebook AI Research under the project name Evolutionary Scale Modeling (ESM). These models are designed to understand and predict various properties of proteins by leveraging the principles of language modeling in a manner similar to how models like GPT-3 process natural language.]]></summary></entry><entry><title type="html">Paper Review - AlphaFold2 and AlphaFold3</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-alphafold2-and-alphafold3/" rel="alternate" type="text/html" title="Paper Review - AlphaFold2 and AlphaFold3"/><published>2024-06-19T10:13:03+00:00</published><updated>2024-06-19T10:13:03+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---alphafold2-and-alphafold3</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-alphafold2-and-alphafold3/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Let's try to figure out whats inside AlphaFold! AlphaFold can accurately predict structures of biomolecular interactions.]]></summary></entry><entry><title type="html">Paper Review - ProteinDT</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-proteindt/" rel="alternate" type="text/html" title="Paper Review - ProteinDT"/><published>2024-06-18T10:13:03+00:00</published><updated>2024-06-18T10:13:03+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---proteindt</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-proteindt/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[ProteinDT is A Opensource Text-guided Protein Design Framework that uses Contrastive learning to align the two modalities.]]></summary></entry><entry><title type="html">Paper Review - Axial Transformer and MSA Transformer</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-axial-transformer-and-msa-transformer/" rel="alternate" type="text/html" title="Paper Review - Axial Transformer and MSA Transformer"/><published>2024-06-17T08:49:25+00:00</published><updated>2024-06-17T08:49:25+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---axial-transformer-and-msa-transformer</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-axial-transformer-and-msa-transformer/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[The Axial Transformer is aimed at managing the complexity of high-dimensional data like images and videos, while The MSA transformer is focused on biological sequences and their alignments.]]></summary></entry><entry><title type="html">Paper Review - InstantID</title><link href="https://kuwingfung.github.io/blog/2024/paper-review-instantid/" rel="alternate" type="text/html" title="Paper Review - InstantID"/><published>2024-06-17T04:14:39+00:00</published><updated>2024-06-17T04:14:39+00:00</updated><id>https://kuwingfung.github.io/blog/2024/paper-review---instantid</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/paper-review-instantid/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Identity-Perserving Generation task refers to synthesizing an image that contains a desired person's identity. InstantID tackles this task with only one reference facial image. Moreover, InstantID does not require test-time training while utilizing the learned prior from diffusion-based foundation models like Stable Diffusion. Such methodology is highly efficient compared to previous methods that require fine-tuning on the foundation model. According to the paper, this work shows superior results in Identity-Perserving Generation, outperforming LoRA-based and IP-adapter-based methods qualitatively.]]></summary></entry><entry><title type="html">Notes on Video Diffusion Models</title><link href="https://kuwingfung.github.io/blog/2024/notes-on-video-diffusion-models/" rel="alternate" type="text/html" title="Notes on Video Diffusion Models"/><published>2024-01-26T23:53:48+00:00</published><updated>2024-01-26T23:53:48+00:00</updated><id>https://kuwingfung.github.io/blog/2024/notes-on-video-diffusion-models</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2024/notes-on-video-diffusion-models/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[My handwritten notes on Video Diffusion models. Includes TokenFlow, Fairy, LaVie]]></summary></entry></feed>