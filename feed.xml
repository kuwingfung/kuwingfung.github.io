<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://kuwingfung.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kuwingfung.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-19T03:58:05+00:00</updated><id>https://kuwingfung.github.io/feed.xml</id><title type="html">Max W.F. Ku</title><subtitle>Academic page of Max Ku. </subtitle><entry><title type="html">Notes on Improving Physics in Visual World Generation</title><link href="https://kuwingfung.github.io/blog/2026/notes-on-improving-physics-in-visual-world-generation/" rel="alternate" type="text/html" title="Notes on Improving Physics in Visual World Generation"/><published>2026-02-03T08:51:55+00:00</published><updated>2026-02-03T08:51:55+00:00</updated><id>https://kuwingfung.github.io/blog/2026/notes-on-improving-physics-in-visual-world-generation</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/notes-on-improving-physics-in-visual-world-generation/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Self-Refining Video Sampling (Jan 26) <a]]></summary></entry><entry><title type="html">Notes on Video Models Events</title><link href="https://kuwingfung.github.io/blog/2026/notes-on-video-models-events/" rel="alternate" type="text/html" title="Notes on Video Models Events"/><published>2026-01-30T08:13:30+00:00</published><updated>2026-01-30T08:13:30+00:00</updated><id>https://kuwingfung.github.io/blog/2026/notes-on-video-models-events</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/notes-on-video-models-events/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[WorldCanvas (Dec 25’) The World is Your Canvas: Painting]]></summary></entry><entry><title type="html">Notes on Video Model Efficency</title><link href="https://kuwingfung.github.io/blog/2026/notes-on-video-model-efficency/" rel="alternate" type="text/html" title="Notes on Video Model Efficency"/><published>2026-01-30T08:13:18+00:00</published><updated>2026-01-30T08:13:18+00:00</updated><id>https://kuwingfung.github.io/blog/2026/notes-on-video-model-efficency</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/notes-on-video-model-efficency/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[FastVideo FastVideo is a unified post-training and inference framework for accelerated video]]></summary></entry><entry><title type="html">Notes on Playable World Models</title><link href="https://kuwingfung.github.io/blog/2026/notes-on-playable-world-models/" rel="alternate" type="text/html" title="Notes on Playable World Models"/><published>2026-01-28T03:43:21+00:00</published><updated>2026-01-28T03:43:21+00:00</updated><id>https://kuwingfung.github.io/blog/2026/notes-on-playable-world-models</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/notes-on-playable-world-models/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Playable World Models Work / System Main]]></summary></entry><entry><title type="html">Exponential Moving Average (EMA) in PyTorch</title><link href="https://kuwingfung.github.io/blog/2026/exponential-moving-average-ema-in-pytorch/" rel="alternate" type="text/html" title="Exponential Moving Average (EMA) in PyTorch"/><published>2026-01-25T05:24:02+00:00</published><updated>2026-01-25T05:24:02+00:00</updated><id>https://kuwingfung.github.io/blog/2026/exponential-moving-average-ema-in-pytorch</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/exponential-moving-average-ema-in-pytorch/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[A quick notes on what EMA is]]></summary></entry><entry><title type="html">Seminar in Cognitive Science Summary and Thoughts</title><link href="https://kuwingfung.github.io/blog/2026/seminar-in-cognitive-science-summary-and-thoughts/" rel="alternate" type="text/html" title="Seminar in Cognitive Science Summary and Thoughts"/><published>2026-01-25T04:32:33+00:00</published><updated>2026-01-25T04:32:33+00:00</updated><id>https://kuwingfung.github.io/blog/2026/seminar-in-cognitive-science-summary-and-thoughts</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/seminar-in-cognitive-science-summary-and-thoughts/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[My write up notes for Winter 2026 COGSCI600 Cognitive Science Seminar. Summary by Max Ku (Me).]]></summary></entry><entry><title type="html">Notes on World Models Agents</title><link href="https://kuwingfung.github.io/blog/2026/notes-on-world-models-agents/" rel="alternate" type="text/html" title="Notes on World Models Agents"/><published>2026-01-21T07:48:45+00:00</published><updated>2026-01-21T07:48:45+00:00</updated><id>https://kuwingfung.github.io/blog/2026/notes-on-world-models-agents</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/notes-on-world-models-agents/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[SIMA 2 (Dec 25’) SIMA 2: A Generalist Embodied Agent for Virtual]]></summary></entry><entry><title type="html">Notes on World Models Memories</title><link href="https://kuwingfung.github.io/blog/2026/notes-on-world-models-memories/" rel="alternate" type="text/html" title="Notes on World Models Memories"/><published>2026-01-21T00:56:15+00:00</published><updated>2026-01-21T00:56:15+00:00</updated><id>https://kuwingfung.github.io/blog/2026/notes-on-world-models-memories</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/notes-on-world-models-memories/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[World Models Memories FlowWM (Jan, 26’) Flow]]></summary></entry><entry><title type="html">JEPA (Joint-Embedding Predictive Architecture)</title><link href="https://kuwingfung.github.io/blog/2026/jepa-joint-embedding-predictive-architecture/" rel="alternate" type="text/html" title="JEPA (Joint-Embedding Predictive Architecture)"/><published>2026-01-09T05:08:30+00:00</published><updated>2026-01-09T05:08:30+00:00</updated><id>https://kuwingfung.github.io/blog/2026/jepa-joint-embedding-predictive-architecture</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2026/jepa-joint-embedding-predictive-architecture/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[JEPA (Joint-Embedding Predictive Architecture) is a self-supervised learning method that predicts abstract representations of missing data (targets) from visible data (context) in a shared latent space, avoiding direct pixel prediction or contrastive forces, leading to more semantic, stable, and efficient learning for tasks like image and video understanding by focusing on core concepts rather than pixel details.]]></summary></entry><entry><title type="html">From Cold Emails to Gravity Wells</title><link href="https://kuwingfung.github.io/blog/2025/from-cold-emails-to-gravity-wells/" rel="alternate" type="text/html" title="From Cold Emails to Gravity Wells"/><published>2025-10-24T15:55:31+00:00</published><updated>2025-10-24T15:55:31+00:00</updated><id>https://kuwingfung.github.io/blog/2025/from-cold-emails-to-gravity-wells</id><content type="html" xml:base="https://kuwingfung.github.io/blog/2025/from-cold-emails-to-gravity-wells/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Some thoughts after a year into my CS PhD.]]></summary></entry></feed>